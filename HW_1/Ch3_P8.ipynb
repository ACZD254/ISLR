{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">8.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "# The following initialisations are completely unncessary in my opinion. I am going to comment them out and see what happens.\n",
    "pd.set_option('display.precision', 2) # number precision for pandas\n",
    "pd.set_option('display.max_rows', 10)\n",
    "# pd.set_option('display.float_format', '{:20,.2f}'.format) # get rid of scientific notation\n",
    "# plt.style.use('seaborn') # pretty matplotlib plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Dataset \n",
    "Auto = pd.read_csv(r\"C:\\Users\\smtrp\\OneDrive\\Desktop\\DS502\\ISLR\\Data_Sets\\Auto.csv\")\n",
    "#Dropping NAN values\n",
    "Auto.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8a**\n",
    "Okay, so due to my familiarity with this, I should be able to get through this with relative ease now. lets see. Just going to use sklearn here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '?'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\smtrp\\OneDrive\\Desktop\\DS502\\ISLR\\HW_1\\Ch3_P8.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/smtrp/OneDrive/Desktop/DS502/ISLR/HW_1/Ch3_P8.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m x_data \u001b[39m=\u001b[39m Auto\u001b[39m.\u001b[39mloc[:,\u001b[39m'\u001b[39m\u001b[39mhorsepower\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39marray\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/smtrp/OneDrive/Desktop/DS502/ISLR/HW_1/Ch3_P8.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m y_data \u001b[39m=\u001b[39m Auto\u001b[39m.\u001b[39mloc[:,\u001b[39m'\u001b[39m\u001b[39mmpg\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39marray\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/smtrp/OneDrive/Desktop/DS502/ISLR/HW_1/Ch3_P8.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m lm_fit \u001b[39m=\u001b[39m lm\u001b[39m.\u001b[39;49mfit(y_data,x_data)\n",
      "File \u001b[1;32mc:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:662\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    658\u001b[0m n_jobs_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs\n\u001b[0;32m    660\u001b[0m accept_sparse \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositive \u001b[39melse\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 662\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    663\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse, y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m    664\u001b[0m )\n\u001b[0;32m    666\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    667\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    582\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:979\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my cannot be None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    964\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    965\u001b[0m     X,\n\u001b[0;32m    966\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    976\u001b[0m     estimator\u001b[39m=\u001b[39mestimator,\n\u001b[0;32m    977\u001b[0m )\n\u001b[1;32m--> 979\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39;49mmulti_output, y_numeric\u001b[39m=\u001b[39;49my_numeric)\n\u001b[0;32m    981\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m    983\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:997\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric)\u001b[0m\n\u001b[0;32m    995\u001b[0m     _ensure_no_complex_data(y)\n\u001b[0;32m    996\u001b[0m \u001b[39mif\u001b[39;00m y_numeric \u001b[39mand\u001b[39;00m y\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mO\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 997\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat64)\n\u001b[0;32m    999\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '?'"
     ]
    }
   ],
   "source": [
    "# Importing linear model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm= LinearRegression()\n",
    "x_data = Auto.loc[:,'horsepower'].array.reshape(1,-1)\n",
    "y_data = Auto.loc[:,'mpg'].array.reshape(1,-1)\n",
    "lm_fit = lm.fit(y_data,x_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note for Isaac**\n",
    "Dear Isaac, why is the code above not working? Like wtf? I have tried all possible combinations of array orientations and this error had cropped up before with auto data. Am I doing something wrong? Now I can't use sklearn to solve this and will have to use the very unintuitive statmodels instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.795</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.731</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.60</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 23 Nov 2022</td> <th>  Prob (F-statistic):</th> <td>2.79e-64</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:45:19</td>     <th>  Log-Likelihood:    </th> <td> -1065.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   397</td>      <th>  AIC:               </th> <td>   2319.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   303</td>      <th>  BIC:               </th> <td>   2694.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    93</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>         <td>   19.5941</td> <td>    0.984</td> <td>   19.920</td> <td> 0.000</td> <td>   17.658</td> <td>   21.530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.102]</th> <td>    0.4059</td> <td>    4.173</td> <td>    0.097</td> <td> 0.923</td> <td>   -7.806</td> <td>    8.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.103]</th> <td>    0.7059</td> <td>    4.173</td> <td>    0.169</td> <td> 0.866</td> <td>   -7.506</td> <td>    8.918</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.105]</th> <td>    0.9059</td> <td>    1.529</td> <td>    0.592</td> <td> 0.554</td> <td>   -2.103</td> <td>    3.915</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.107]</th> <td>    1.4059</td> <td>    4.173</td> <td>    0.337</td> <td> 0.736</td> <td>   -6.806</td> <td>    9.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.108]</th> <td>   -0.5941</td> <td>    4.173</td> <td>   -0.142</td> <td> 0.887</td> <td>   -8.806</td> <td>    7.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.110]</th> <td>    0.2392</td> <td>    1.372</td> <td>    0.174</td> <td> 0.862</td> <td>   -2.460</td> <td>    2.938</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.112]</th> <td>    0.0725</td> <td>    2.540</td> <td>    0.029</td> <td> 0.977</td> <td>   -4.925</td> <td>    5.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.113]</th> <td>    6.4059</td> <td>    4.173</td> <td>    1.535</td> <td> 0.126</td> <td>   -1.806</td> <td>   14.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.115]</th> <td>    5.1459</td> <td>    2.063</td> <td>    2.494</td> <td> 0.013</td> <td>    1.086</td> <td>    9.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.116]</th> <td>    5.8059</td> <td>    4.173</td> <td>    1.391</td> <td> 0.165</td> <td>   -2.406</td> <td>   14.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.120]</th> <td>   -1.0191</td> <td>    2.254</td> <td>   -0.452</td> <td> 0.651</td> <td>   -5.454</td> <td>    3.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.122]</th> <td>    0.4059</td> <td>    4.173</td> <td>    0.097</td> <td> 0.923</td> <td>   -7.806</td> <td>    8.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.125]</th> <td>    0.1392</td> <td>    2.540</td> <td>    0.055</td> <td> 0.956</td> <td>   -4.859</td> <td>    5.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.129]</th> <td>   -4.2941</td> <td>    3.032</td> <td>   -1.416</td> <td> 0.158</td> <td>  -10.260</td> <td>    1.672</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.130]</th> <td>   -4.3941</td> <td>    2.063</td> <td>   -2.130</td> <td> 0.034</td> <td>   -8.454</td> <td>   -0.334</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.132]</th> <td>   13.1059</td> <td>    4.173</td> <td>    3.140</td> <td> 0.002</td> <td>    4.894</td> <td>   21.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.133]</th> <td>   -3.3941</td> <td>    4.173</td> <td>   -0.813</td> <td> 0.417</td> <td>  -11.606</td> <td>    4.818</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.135]</th> <td>   -1.3941</td> <td>    4.173</td> <td>   -0.334</td> <td> 0.739</td> <td>   -9.606</td> <td>    6.818</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.137]</th> <td>   -5.5941</td> <td>    4.173</td> <td>   -1.340</td> <td> 0.181</td> <td>  -13.806</td> <td>    2.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.138]</th> <td>   -3.0941</td> <td>    4.173</td> <td>   -0.741</td> <td> 0.459</td> <td>  -11.306</td> <td>    5.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.139]</th> <td>   -0.4441</td> <td>    3.032</td> <td>   -0.146</td> <td> 0.884</td> <td>   -6.410</td> <td>    5.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.140]</th> <td>   -3.2513</td> <td>    1.821</td> <td>   -1.785</td> <td> 0.075</td> <td>   -6.835</td> <td>    0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.142]</th> <td>   -4.0941</td> <td>    4.173</td> <td>   -0.981</td> <td> 0.327</td> <td>  -12.306</td> <td>    4.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.145]</th> <td>   -4.1370</td> <td>    1.821</td> <td>   -2.271</td> <td> 0.024</td> <td>   -7.721</td> <td>   -0.553</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.148]</th> <td>   -5.5941</td> <td>    4.173</td> <td>   -1.340</td> <td> 0.181</td> <td>  -13.806</td> <td>    2.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.149]</th> <td>   -3.5941</td> <td>    4.173</td> <td>   -0.861</td> <td> 0.390</td> <td>  -11.806</td> <td>    4.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.150]</th> <td>   -4.8896</td> <td>    1.310</td> <td>   -3.733</td> <td> 0.000</td> <td>   -7.467</td> <td>   -2.312</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.152]</th> <td>   -5.0941</td> <td>    4.173</td> <td>   -1.221</td> <td> 0.223</td> <td>  -13.306</td> <td>    3.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.153]</th> <td>   -5.5941</td> <td>    3.032</td> <td>   -1.845</td> <td> 0.066</td> <td>  -11.560</td> <td>    0.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.155]</th> <td>   -4.6441</td> <td>    3.032</td> <td>   -1.532</td> <td> 0.127</td> <td>  -10.610</td> <td>    1.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.158]</th> <td>   -6.5941</td> <td>    4.173</td> <td>   -1.580</td> <td> 0.115</td> <td>  -14.806</td> <td>    1.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.160]</th> <td>   -6.5941</td> <td>    3.032</td> <td>   -2.175</td> <td> 0.030</td> <td>  -12.560</td> <td>   -0.628</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.165]</th> <td>   -4.6691</td> <td>    2.254</td> <td>   -2.072</td> <td> 0.039</td> <td>   -9.104</td> <td>   -0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.167]</th> <td>   -7.5941</td> <td>    4.173</td> <td>   -1.820</td> <td> 0.070</td> <td>  -15.806</td> <td>    0.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.170]</th> <td>   -5.0941</td> <td>    2.063</td> <td>   -2.469</td> <td> 0.014</td> <td>   -9.154</td> <td>   -1.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.175]</th> <td>   -6.1941</td> <td>    2.063</td> <td>   -3.002</td> <td> 0.003</td> <td>  -10.254</td> <td>   -2.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.180]</th> <td>   -6.0941</td> <td>    2.063</td> <td>   -2.954</td> <td> 0.003</td> <td>  -10.154</td> <td>   -2.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.190]</th> <td>   -5.0941</td> <td>    2.540</td> <td>   -2.006</td> <td> 0.046</td> <td>  -10.092</td> <td>   -0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.193]</th> <td>  -10.5941</td> <td>    4.173</td> <td>   -2.539</td> <td> 0.012</td> <td>  -18.806</td> <td>   -2.382</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.198]</th> <td>   -6.0941</td> <td>    3.032</td> <td>   -2.010</td> <td> 0.045</td> <td>  -12.060</td> <td>   -0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.200]</th> <td>   -9.5941</td> <td>    4.173</td> <td>   -2.299</td> <td> 0.022</td> <td>  -17.806</td> <td>   -1.382</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.208]</th> <td>   -8.5941</td> <td>    4.173</td> <td>   -2.059</td> <td> 0.040</td> <td>  -16.806</td> <td>   -0.382</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.210]</th> <td>   -8.5941</td> <td>    4.173</td> <td>   -2.059</td> <td> 0.040</td> <td>  -16.806</td> <td>   -0.382</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.215]</th> <td>   -7.2608</td> <td>    2.540</td> <td>   -2.859</td> <td> 0.005</td> <td>  -12.259</td> <td>   -2.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.220]</th> <td>   -5.5941</td> <td>    4.173</td> <td>   -1.340</td> <td> 0.181</td> <td>  -13.806</td> <td>    2.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.225]</th> <td>   -6.2608</td> <td>    2.540</td> <td>   -2.465</td> <td> 0.014</td> <td>  -11.259</td> <td>   -1.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.230]</th> <td>   -3.5941</td> <td>    4.173</td> <td>   -0.861</td> <td> 0.390</td> <td>  -11.806</td> <td>    4.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.46]</th>  <td>    6.4059</td> <td>    3.032</td> <td>    2.113</td> <td> 0.035</td> <td>    0.440</td> <td>   12.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.48]</th>  <td>   24.0059</td> <td>    2.540</td> <td>    9.452</td> <td> 0.000</td> <td>   19.008</td> <td>   29.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.49]</th>  <td>    9.4059</td> <td>    4.173</td> <td>    2.254</td> <td> 0.025</td> <td>    1.194</td> <td>   17.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.52]</th>  <td>   14.6059</td> <td>    2.254</td> <td>    6.481</td> <td> 0.000</td> <td>   10.171</td> <td>   19.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.53]</th>  <td>   13.4059</td> <td>    3.032</td> <td>    4.422</td> <td> 0.000</td> <td>    7.440</td> <td>   19.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.54]</th>  <td>    3.4059</td> <td>    4.173</td> <td>    0.816</td> <td> 0.415</td> <td>   -4.806</td> <td>   11.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.58]</th>  <td>   17.9559</td> <td>    3.032</td> <td>    5.923</td> <td> 0.000</td> <td>   11.990</td> <td>   23.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.60]</th>  <td>   12.5659</td> <td>    2.063</td> <td>    6.090</td> <td> 0.000</td> <td>    8.506</td> <td>   16.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.61]</th>  <td>   12.4059</td> <td>    4.173</td> <td>    2.973</td> <td> 0.003</td> <td>    4.194</td> <td>   20.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.62]</th>  <td>   14.1559</td> <td>    3.032</td> <td>    4.669</td> <td> 0.000</td> <td>    8.190</td> <td>   20.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.63]</th>  <td>   14.8059</td> <td>    2.540</td> <td>    5.830</td> <td> 0.000</td> <td>    9.808</td> <td>   19.804</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.64]</th>  <td>   19.4059</td> <td>    4.173</td> <td>    4.650</td> <td> 0.000</td> <td>   11.194</td> <td>   27.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.65]</th>  <td>   15.8859</td> <td>    1.616</td> <td>    9.829</td> <td> 0.000</td> <td>   12.705</td> <td>   19.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.66]</th>  <td>   16.5059</td> <td>    4.173</td> <td>    3.955</td> <td> 0.000</td> <td>    8.294</td> <td>   24.718</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.67]</th>  <td>   13.9975</td> <td>    1.529</td> <td>    9.154</td> <td> 0.000</td> <td>   10.989</td> <td>   17.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.68]</th>  <td>   12.5892</td> <td>    1.926</td> <td>    6.537</td> <td> 0.000</td> <td>    8.799</td> <td>   16.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.69]</th>  <td>   13.1725</td> <td>    2.540</td> <td>    5.187</td> <td> 0.000</td> <td>    8.175</td> <td>   18.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.70]</th>  <td>   12.8809</td> <td>    1.529</td> <td>    8.424</td> <td> 0.000</td> <td>    9.872</td> <td>   15.890</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.71]</th>  <td>    9.4259</td> <td>    2.063</td> <td>    4.568</td> <td> 0.000</td> <td>    5.366</td> <td>   13.486</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.72]</th>  <td>    2.3892</td> <td>    1.926</td> <td>    1.241</td> <td> 0.216</td> <td>   -1.401</td> <td>    6.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.74]</th>  <td>   13.9392</td> <td>    2.540</td> <td>    5.488</td> <td> 0.000</td> <td>    8.941</td> <td>   18.937</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.75]</th>  <td>    9.4416</td> <td>    1.464</td> <td>    6.451</td> <td> 0.000</td> <td>    6.561</td> <td>   12.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.76]</th>  <td>   11.4559</td> <td>    2.254</td> <td>    5.083</td> <td> 0.000</td> <td>    7.021</td> <td>   15.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.77]</th>  <td>    5.8059</td> <td>    4.173</td> <td>    1.391</td> <td> 0.165</td> <td>   -2.406</td> <td>   14.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.78]</th>  <td>    7.2059</td> <td>    1.926</td> <td>    3.742</td> <td> 0.000</td> <td>    3.416</td> <td>   10.996</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.79]</th>  <td>    7.4059</td> <td>    3.032</td> <td>    2.443</td> <td> 0.015</td> <td>    1.440</td> <td>   13.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.80]</th>  <td>    9.0059</td> <td>    1.821</td> <td>    4.945</td> <td> 0.000</td> <td>    5.422</td> <td>   12.590</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.81]</th>  <td>    4.9059</td> <td>    3.032</td> <td>    1.618</td> <td> 0.107</td> <td>   -1.060</td> <td>   10.872</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.82]</th>  <td>   11.4059</td> <td>    4.173</td> <td>    2.733</td> <td> 0.007</td> <td>    3.194</td> <td>   19.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.83]</th>  <td>    8.5309</td> <td>    2.254</td> <td>    3.785</td> <td> 0.000</td> <td>    4.096</td> <td>   12.966</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.84]</th>  <td>   10.5392</td> <td>    1.926</td> <td>    5.473</td> <td> 0.000</td> <td>    6.749</td> <td>   14.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.85]</th>  <td>    3.8725</td> <td>    1.672</td> <td>    2.316</td> <td> 0.021</td> <td>    0.583</td> <td>    7.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.86]</th>  <td>    4.6059</td> <td>    2.063</td> <td>    2.232</td> <td> 0.026</td> <td>    0.546</td> <td>    8.666</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.87]</th>  <td>    3.4059</td> <td>    3.032</td> <td>    1.123</td> <td> 0.262</td> <td>   -2.560</td> <td>    9.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.88]</th>  <td>    5.4848</td> <td>    1.354</td> <td>    4.051</td> <td> 0.000</td> <td>    2.820</td> <td>    8.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.89]</th>  <td>    5.9059</td> <td>    4.173</td> <td>    1.415</td> <td> 0.158</td> <td>   -2.306</td> <td>   14.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.90]</th>  <td>    4.7609</td> <td>    1.338</td> <td>    3.559</td> <td> 0.000</td> <td>    2.128</td> <td>    7.394</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.91]</th>  <td>    0.4059</td> <td>    4.173</td> <td>    0.097</td> <td> 0.923</td> <td>   -7.806</td> <td>    8.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.92]</th>  <td>    8.0392</td> <td>    1.926</td> <td>    4.174</td> <td> 0.000</td> <td>    4.249</td> <td>   11.829</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.93]</th>  <td>    6.4059</td> <td>    4.173</td> <td>    1.535</td> <td> 0.126</td> <td>   -1.806</td> <td>   14.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.94]</th>  <td>    2.4059</td> <td>    4.173</td> <td>    0.577</td> <td> 0.565</td> <td>   -5.806</td> <td>   10.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.95]</th>  <td>    2.5202</td> <td>    1.464</td> <td>    1.722</td> <td> 0.086</td> <td>   -0.360</td> <td>    5.400</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.96]</th>  <td>    7.5725</td> <td>    2.540</td> <td>    2.982</td> <td> 0.003</td> <td>    2.575</td> <td>   12.570</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.97]</th>  <td>    2.5281</td> <td>    1.672</td> <td>    1.512</td> <td> 0.132</td> <td>   -0.762</td> <td>    5.818</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.98]</th>  <td>    0.6559</td> <td>    3.032</td> <td>    0.216</td> <td> 0.829</td> <td>   -5.310</td> <td>    6.622</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower[T.?]</th>   <td>    9.4059</td> <td>    2.063</td> <td>    4.559</td> <td> 0.000</td> <td>    5.346</td> <td>   13.466</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>52.669</td> <th>  Durbin-Watson:     </th> <td>   1.388</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  95.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.773</td> <th>  Prob(JB):          </th> <td>2.31e-21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.831</td> <th>  Cond. No.          </th> <td>    49.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.795\n",
       "Model:                            OLS   Adj. R-squared:                  0.731\n",
       "Method:                 Least Squares   F-statistic:                     12.60\n",
       "Date:                Wed, 23 Nov 2022   Prob (F-statistic):           2.79e-64\n",
       "Time:                        23:45:19   Log-Likelihood:                -1065.5\n",
       "No. Observations:                 397   AIC:                             2319.\n",
       "Df Residuals:                     303   BIC:                             2694.\n",
       "Df Model:                          93                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "Intercept            19.5941      0.984     19.920      0.000      17.658      21.530\n",
       "horsepower[T.102]     0.4059      4.173      0.097      0.923      -7.806       8.618\n",
       "horsepower[T.103]     0.7059      4.173      0.169      0.866      -7.506       8.918\n",
       "horsepower[T.105]     0.9059      1.529      0.592      0.554      -2.103       3.915\n",
       "horsepower[T.107]     1.4059      4.173      0.337      0.736      -6.806       9.618\n",
       "horsepower[T.108]    -0.5941      4.173     -0.142      0.887      -8.806       7.618\n",
       "horsepower[T.110]     0.2392      1.372      0.174      0.862      -2.460       2.938\n",
       "horsepower[T.112]     0.0725      2.540      0.029      0.977      -4.925       5.070\n",
       "horsepower[T.113]     6.4059      4.173      1.535      0.126      -1.806      14.618\n",
       "horsepower[T.115]     5.1459      2.063      2.494      0.013       1.086       9.206\n",
       "horsepower[T.116]     5.8059      4.173      1.391      0.165      -2.406      14.018\n",
       "horsepower[T.120]    -1.0191      2.254     -0.452      0.651      -5.454       3.416\n",
       "horsepower[T.122]     0.4059      4.173      0.097      0.923      -7.806       8.618\n",
       "horsepower[T.125]     0.1392      2.540      0.055      0.956      -4.859       5.137\n",
       "horsepower[T.129]    -4.2941      3.032     -1.416      0.158     -10.260       1.672\n",
       "horsepower[T.130]    -4.3941      2.063     -2.130      0.034      -8.454      -0.334\n",
       "horsepower[T.132]    13.1059      4.173      3.140      0.002       4.894      21.318\n",
       "horsepower[T.133]    -3.3941      4.173     -0.813      0.417     -11.606       4.818\n",
       "horsepower[T.135]    -1.3941      4.173     -0.334      0.739      -9.606       6.818\n",
       "horsepower[T.137]    -5.5941      4.173     -1.340      0.181     -13.806       2.618\n",
       "horsepower[T.138]    -3.0941      4.173     -0.741      0.459     -11.306       5.118\n",
       "horsepower[T.139]    -0.4441      3.032     -0.146      0.884      -6.410       5.522\n",
       "horsepower[T.140]    -3.2513      1.821     -1.785      0.075      -6.835       0.333\n",
       "horsepower[T.142]    -4.0941      4.173     -0.981      0.327     -12.306       4.118\n",
       "horsepower[T.145]    -4.1370      1.821     -2.271      0.024      -7.721      -0.553\n",
       "horsepower[T.148]    -5.5941      4.173     -1.340      0.181     -13.806       2.618\n",
       "horsepower[T.149]    -3.5941      4.173     -0.861      0.390     -11.806       4.618\n",
       "horsepower[T.150]    -4.8896      1.310     -3.733      0.000      -7.467      -2.312\n",
       "horsepower[T.152]    -5.0941      4.173     -1.221      0.223     -13.306       3.118\n",
       "horsepower[T.153]    -5.5941      3.032     -1.845      0.066     -11.560       0.372\n",
       "horsepower[T.155]    -4.6441      3.032     -1.532      0.127     -10.610       1.322\n",
       "horsepower[T.158]    -6.5941      4.173     -1.580      0.115     -14.806       1.618\n",
       "horsepower[T.160]    -6.5941      3.032     -2.175      0.030     -12.560      -0.628\n",
       "horsepower[T.165]    -4.6691      2.254     -2.072      0.039      -9.104      -0.234\n",
       "horsepower[T.167]    -7.5941      4.173     -1.820      0.070     -15.806       0.618\n",
       "horsepower[T.170]    -5.0941      2.063     -2.469      0.014      -9.154      -1.034\n",
       "horsepower[T.175]    -6.1941      2.063     -3.002      0.003     -10.254      -2.134\n",
       "horsepower[T.180]    -6.0941      2.063     -2.954      0.003     -10.154      -2.034\n",
       "horsepower[T.190]    -5.0941      2.540     -2.006      0.046     -10.092      -0.096\n",
       "horsepower[T.193]   -10.5941      4.173     -2.539      0.012     -18.806      -2.382\n",
       "horsepower[T.198]    -6.0941      3.032     -2.010      0.045     -12.060      -0.128\n",
       "horsepower[T.200]    -9.5941      4.173     -2.299      0.022     -17.806      -1.382\n",
       "horsepower[T.208]    -8.5941      4.173     -2.059      0.040     -16.806      -0.382\n",
       "horsepower[T.210]    -8.5941      4.173     -2.059      0.040     -16.806      -0.382\n",
       "horsepower[T.215]    -7.2608      2.540     -2.859      0.005     -12.259      -2.263\n",
       "horsepower[T.220]    -5.5941      4.173     -1.340      0.181     -13.806       2.618\n",
       "horsepower[T.225]    -6.2608      2.540     -2.465      0.014     -11.259      -1.263\n",
       "horsepower[T.230]    -3.5941      4.173     -0.861      0.390     -11.806       4.618\n",
       "horsepower[T.46]      6.4059      3.032      2.113      0.035       0.440      12.372\n",
       "horsepower[T.48]     24.0059      2.540      9.452      0.000      19.008      29.004\n",
       "horsepower[T.49]      9.4059      4.173      2.254      0.025       1.194      17.618\n",
       "horsepower[T.52]     14.6059      2.254      6.481      0.000      10.171      19.041\n",
       "horsepower[T.53]     13.4059      3.032      4.422      0.000       7.440      19.372\n",
       "horsepower[T.54]      3.4059      4.173      0.816      0.415      -4.806      11.618\n",
       "horsepower[T.58]     17.9559      3.032      5.923      0.000      11.990      23.922\n",
       "horsepower[T.60]     12.5659      2.063      6.090      0.000       8.506      16.626\n",
       "horsepower[T.61]     12.4059      4.173      2.973      0.003       4.194      20.618\n",
       "horsepower[T.62]     14.1559      3.032      4.669      0.000       8.190      20.122\n",
       "horsepower[T.63]     14.8059      2.540      5.830      0.000       9.808      19.804\n",
       "horsepower[T.64]     19.4059      4.173      4.650      0.000      11.194      27.618\n",
       "horsepower[T.65]     15.8859      1.616      9.829      0.000      12.705      19.066\n",
       "horsepower[T.66]     16.5059      4.173      3.955      0.000       8.294      24.718\n",
       "horsepower[T.67]     13.9975      1.529      9.154      0.000      10.989      17.007\n",
       "horsepower[T.68]     12.5892      1.926      6.537      0.000       8.799      16.379\n",
       "horsepower[T.69]     13.1725      2.540      5.187      0.000       8.175      18.170\n",
       "horsepower[T.70]     12.8809      1.529      8.424      0.000       9.872      15.890\n",
       "horsepower[T.71]      9.4259      2.063      4.568      0.000       5.366      13.486\n",
       "horsepower[T.72]      2.3892      1.926      1.241      0.216      -1.401       6.179\n",
       "horsepower[T.74]     13.9392      2.540      5.488      0.000       8.941      18.937\n",
       "horsepower[T.75]      9.4416      1.464      6.451      0.000       6.561      12.322\n",
       "horsepower[T.76]     11.4559      2.254      5.083      0.000       7.021      15.891\n",
       "horsepower[T.77]      5.8059      4.173      1.391      0.165      -2.406      14.018\n",
       "horsepower[T.78]      7.2059      1.926      3.742      0.000       3.416      10.996\n",
       "horsepower[T.79]      7.4059      3.032      2.443      0.015       1.440      13.372\n",
       "horsepower[T.80]      9.0059      1.821      4.945      0.000       5.422      12.590\n",
       "horsepower[T.81]      4.9059      3.032      1.618      0.107      -1.060      10.872\n",
       "horsepower[T.82]     11.4059      4.173      2.733      0.007       3.194      19.618\n",
       "horsepower[T.83]      8.5309      2.254      3.785      0.000       4.096      12.966\n",
       "horsepower[T.84]     10.5392      1.926      5.473      0.000       6.749      14.329\n",
       "horsepower[T.85]      3.8725      1.672      2.316      0.021       0.583       7.162\n",
       "horsepower[T.86]      4.6059      2.063      2.232      0.026       0.546       8.666\n",
       "horsepower[T.87]      3.4059      3.032      1.123      0.262      -2.560       9.372\n",
       "horsepower[T.88]      5.4848      1.354      4.051      0.000       2.820       8.149\n",
       "horsepower[T.89]      5.9059      4.173      1.415      0.158      -2.306      14.118\n",
       "horsepower[T.90]      4.7609      1.338      3.559      0.000       2.128       7.394\n",
       "horsepower[T.91]      0.4059      4.173      0.097      0.923      -7.806       8.618\n",
       "horsepower[T.92]      8.0392      1.926      4.174      0.000       4.249      11.829\n",
       "horsepower[T.93]      6.4059      4.173      1.535      0.126      -1.806      14.618\n",
       "horsepower[T.94]      2.4059      4.173      0.577      0.565      -5.806      10.618\n",
       "horsepower[T.95]      2.5202      1.464      1.722      0.086      -0.360       5.400\n",
       "horsepower[T.96]      7.5725      2.540      2.982      0.003       2.575      12.570\n",
       "horsepower[T.97]      2.5281      1.672      1.512      0.132      -0.762       5.818\n",
       "horsepower[T.98]      0.6559      3.032      0.216      0.829      -5.310       6.622\n",
       "horsepower[T.?]       9.4059      2.063      4.559      0.000       5.346      13.466\n",
       "==============================================================================\n",
       "Omnibus:                       52.669   Durbin-Watson:                   1.388\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               95.031\n",
       "Skew:                           0.773   Prob(JB):                     2.31e-21\n",
       "Kurtosis:                       4.831   Cond. No.                         49.7\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm1 = smf.ols(formula='mpg ~ horsepower', data=Auto)\n",
    "\n",
    "lm1_fit = lm1.fit()\n",
    "lm1_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i & ii : Can't tell as the results seem to be messed up.\\\n",
    "iii : I don't understand this result at all. Like what is this? Why is it split like this?\\\n",
    "iv : will be solved now. Again, the only way I know how to solve this is with sk learn and I am pretty sure that the same error is going to stop me. lets see.\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '?'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\smtrp\\OneDrive\\Desktop\\DS502\\ISLR\\HW_1\\Ch3_P8.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/smtrp/OneDrive/Desktop/DS502/ISLR/HW_1/Ch3_P8.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m x_data \u001b[39m=\u001b[39m Auto[\u001b[39m'\u001b[39m\u001b[39mhorsepower\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/smtrp/OneDrive/Desktop/DS502/ISLR/HW_1/Ch3_P8.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m y_data \u001b[39m=\u001b[39m Auto[\u001b[39m'\u001b[39m\u001b[39mmpg\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/smtrp/OneDrive/Desktop/DS502/ISLR/HW_1/Ch3_P8.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m lm\u001b[39m.\u001b[39;49mfit(x_data, y_data)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/smtrp/OneDrive/Desktop/DS502/ISLR/HW_1/Ch3_P8.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# summary\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/smtrp/OneDrive/Desktop/DS502/ISLR/HW_1/Ch3_P8.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m lm\u001b[39m.\u001b[39mintercept_, lm\u001b[39m.\u001b[39mcoef_\n",
      "File \u001b[1;32mc:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:662\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    658\u001b[0m n_jobs_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs\n\u001b[0;32m    660\u001b[0m accept_sparse \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositive \u001b[39melse\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 662\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    663\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse, y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m    664\u001b[0m )\n\u001b[0;32m    666\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    667\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    582\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my cannot be None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 964\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    965\u001b[0m     X,\n\u001b[0;32m    966\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m    967\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m    968\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    969\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m    970\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    971\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    972\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m    973\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m    974\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m    975\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m    976\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    977\u001b[0m )\n\u001b[0;32m    979\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric)\n\u001b[0;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    747\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '?'"
     ]
    }
   ],
   "source": [
    "# ols model with intercept\n",
    "lm = LinearRegression() \n",
    "x_data = Auto['horsepower'].values.reshape(-1, 1)\n",
    "y_data = Auto['mpg']\n",
    "lm.fit(x_data, y_data)\n",
    "\n",
    "# summary\n",
    "lm.intercept_, lm.coef_\n",
    "\n",
    "lm.predict(np.array([98]).reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8b and 8c**\n",
    "Just for the record, I hate auto data.\n",
    "The following code has been adopted from a repository I found online just to test whether it was working. Its not. I think that my version of Auto data might be corrupted? I don't know. But this solution should work, as I can't see any coding gaffes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:696: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return self.resid / sigma / np.sqrt(1 - hii)\n",
      "c:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:696: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return self.resid / sigma / np.sqrt(1 - hii)\n",
      "c:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "alpha must be numeric or None, not a string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\smtrp\\OneDrive\\Desktop\\DS502\\ISLR\\HW_1\\Ch3_P8.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/smtrp/OneDrive/Desktop/DS502/ISLR/HW_1/Ch3_P8.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m f\u001b[39m.\u001b[39mset_figheight(\u001b[39m10\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/smtrp/OneDrive/Desktop/DS502/ISLR/HW_1/Ch3_P8.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m f\u001b[39m.\u001b[39mset_figwidth(\u001b[39m15\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/smtrp/OneDrive/Desktop/DS502/ISLR/HW_1/Ch3_P8.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m sns\u001b[39m.\u001b[39;49mregplot(\u001b[39m'\u001b[39;49m\u001b[39mhorsepower\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mmpg\u001b[39;49m\u001b[39m'\u001b[39;49m, data\u001b[39m=\u001b[39;49mAuto, ax\u001b[39m=\u001b[39;49maxes[\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m], scatter_kws\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39malpha\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39m0.5\u001b[39;49m\u001b[39m'\u001b[39;49m}) \u001b[39m# regression plot\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/smtrp/OneDrive/Desktop/DS502/ISLR/HW_1/Ch3_P8.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m sns\u001b[39m.\u001b[39mresidplot(y_pred, \u001b[39m'\u001b[39m\u001b[39mmpg\u001b[39m\u001b[39m'\u001b[39m, data\u001b[39m=\u001b[39mAuto, ax\u001b[39m=\u001b[39maxes[\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m], lowess\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/smtrp/OneDrive/Desktop/DS502/ISLR/HW_1/Ch3_P8.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m               scatter_kws\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39m0.5\u001b[39m\u001b[39m'\u001b[39m},\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/smtrp/OneDrive/Desktop/DS502/ISLR/HW_1/Ch3_P8.ipynb#X14sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m               line_kws\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mcolor\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mred\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlw\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.8\u001b[39m}) \u001b[39m# residual plot\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/smtrp/OneDrive/Desktop/DS502/ISLR/HW_1/Ch3_P8.ipynb#X14sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# leverage plot\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:46\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m     37\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPass the following variable\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m as \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39mkeyword arg\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFrom version 0.12, the only valid positional argument \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     )\n\u001b[0;32m     45\u001b[0m kwargs\u001b[39m.\u001b[39mupdate({k: arg \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args)})\n\u001b[1;32m---> 46\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\seaborn\\regression.py:863\u001b[0m, in \u001b[0;36mregplot\u001b[1;34m(x, y, data, x_estimator, x_bins, x_ci, scatter, fit_reg, ci, n_boot, units, seed, order, logistic, lowess, robust, logx, x_partial, y_partial, truncate, dropna, x_jitter, y_jitter, label, color, marker, scatter_kws, line_kws, ax)\u001b[0m\n\u001b[0;32m    861\u001b[0m scatter_kws[\u001b[39m\"\u001b[39m\u001b[39mmarker\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m marker\n\u001b[0;32m    862\u001b[0m line_kws \u001b[39m=\u001b[39m {} \u001b[39mif\u001b[39;00m line_kws \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m copy\u001b[39m.\u001b[39mcopy(line_kws)\n\u001b[1;32m--> 863\u001b[0m plotter\u001b[39m.\u001b[39;49mplot(ax, scatter_kws, line_kws)\n\u001b[0;32m    864\u001b[0m \u001b[39mreturn\u001b[39;00m ax\n",
      "File \u001b[1;32mc:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\seaborn\\regression.py:367\u001b[0m, in \u001b[0;36m_RegressionPlotter.plot\u001b[1;34m(self, ax, scatter_kws, line_kws)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[39m# Draw the constituent plots\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscatter:\n\u001b[1;32m--> 367\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscatterplot(ax, scatter_kws)\n\u001b[0;32m    369\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_reg:\n\u001b[0;32m    370\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineplot(ax, line_kws)\n",
      "File \u001b[1;32mc:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\seaborn\\regression.py:397\u001b[0m, in \u001b[0;36m_RegressionPlotter.scatterplot\u001b[1;34m(self, ax, kws)\u001b[0m\n\u001b[0;32m    394\u001b[0m         kws\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m.8\u001b[39m)\n\u001b[0;32m    396\u001b[0m     x, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscatter_data\n\u001b[1;32m--> 397\u001b[0m     ax\u001b[39m.\u001b[39mscatter(x, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkws)\n\u001b[0;32m    398\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    399\u001b[0m     \u001b[39m# TODO abstraction\u001b[39;00m\n\u001b[0;32m    400\u001b[0m     ci_kws \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mcolor\u001b[39m\u001b[39m\"\u001b[39m: kws[\u001b[39m\"\u001b[39m\u001b[39mcolor\u001b[39m\u001b[39m\"\u001b[39m]}\n",
      "File \u001b[1;32mc:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:1412\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m   1410\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1411\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1412\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(sanitize_sequence, args), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1414\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1415\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[0;32m   1416\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:4458\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4452\u001b[0m         linewidths \u001b[39m=\u001b[39m [\n\u001b[0;32m   4453\u001b[0m             lw \u001b[39mif\u001b[39;00m lw \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m rcParams[\u001b[39m'\u001b[39m\u001b[39mlines.linewidth\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m   4454\u001b[0m             \u001b[39mfor\u001b[39;00m lw \u001b[39min\u001b[39;00m linewidths]\n\u001b[0;32m   4456\u001b[0m offsets \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mcolumn_stack([x, y])\n\u001b[1;32m-> 4458\u001b[0m collection \u001b[39m=\u001b[39m mcoll\u001b[39m.\u001b[39;49mPathCollection(\n\u001b[0;32m   4459\u001b[0m         (path,), scales,\n\u001b[0;32m   4460\u001b[0m         facecolors\u001b[39m=\u001b[39;49mcolors,\n\u001b[0;32m   4461\u001b[0m         edgecolors\u001b[39m=\u001b[39;49medgecolors,\n\u001b[0;32m   4462\u001b[0m         linewidths\u001b[39m=\u001b[39;49mlinewidths,\n\u001b[0;32m   4463\u001b[0m         offsets\u001b[39m=\u001b[39;49moffsets,\n\u001b[0;32m   4464\u001b[0m         transOffset\u001b[39m=\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mpop(\u001b[39m'\u001b[39;49m\u001b[39mtransform\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransData),\n\u001b[0;32m   4465\u001b[0m         alpha\u001b[39m=\u001b[39;49malpha\n\u001b[0;32m   4466\u001b[0m         )\n\u001b[0;32m   4467\u001b[0m collection\u001b[39m.\u001b[39mset_transform(mtransforms\u001b[39m.\u001b[39mIdentityTransform())\n\u001b[0;32m   4468\u001b[0m collection\u001b[39m.\u001b[39mupdate(kwargs)\n",
      "File \u001b[1;32mc:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\matplotlib\\collections.py:1013\u001b[0m, in \u001b[0;36mPathCollection.__init__\u001b[1;34m(self, paths, sizes, **kwargs)\u001b[0m\n\u001b[0;32m    999\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, paths, sizes\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1000\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m \u001b[39m    ----------\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[39m        Forwarded to `.Collection`.\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1013\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1014\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_paths(paths)\n\u001b[0;32m   1015\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_sizes(sizes)\n",
      "File \u001b[1;32mc:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\matplotlib\\collections.py:221\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[1;34m(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, transOffset, norm, cmap, pickradius, hatch, urls, zorder, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transOffset \u001b[39m=\u001b[39m transOffset\n\u001b[0;32m    220\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path_effects \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(kwargs)\n\u001b[0;32m    222\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_paths \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py:1066\u001b[0m, in \u001b[0;36mArtist.update\u001b[1;34m(self, props)\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(func):\n\u001b[0;32m   1064\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m object \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1065\u001b[0m                                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhas no property \u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1066\u001b[0m             ret\u001b[39m.\u001b[39mappend(func(v))\n\u001b[0;32m   1067\u001b[0m \u001b[39mif\u001b[39;00m ret:\n\u001b[0;32m   1068\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpchanged()\n",
      "File \u001b[1;32mc:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\matplotlib\\collections.py:834\u001b[0m, in \u001b[0;36mCollection.set_alpha\u001b[1;34m(self, alpha)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_alpha\u001b[39m(\u001b[39mself\u001b[39m, alpha):\n\u001b[0;32m    823\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    824\u001b[0m \u001b[39m    Set the transparency of the collection.\u001b[39;00m\n\u001b[0;32m    825\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[39m        supported.\u001b[39;00m\n\u001b[0;32m    833\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 834\u001b[0m     artist\u001b[39m.\u001b[39;49mArtist\u001b[39m.\u001b[39;49m_set_alpha_for_array(\u001b[39mself\u001b[39;49m, alpha)\n\u001b[0;32m    835\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_facecolor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_facecolor)\n\u001b[0;32m    836\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_edgecolor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_edgecolor)\n",
      "File \u001b[1;32mc:\\Users\\smtrp\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py:989\u001b[0m, in \u001b[0;36mArtist._set_alpha_for_array\u001b[1;34m(self, alpha)\u001b[0m\n\u001b[0;32m    979\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    980\u001b[0m \u001b[39mSet the alpha value used for blending - not supported on all backends.\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[39m    Masked values and nans are not supported.\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(alpha, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 989\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39malpha must be numeric or None, not a string\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    990\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39miterable(alpha):\n\u001b[0;32m    991\u001b[0m     Artist\u001b[39m.\u001b[39mset_alpha(\u001b[39mself\u001b[39m, alpha)\n",
      "\u001b[1;31mTypeError\u001b[0m: alpha must be numeric or None, not a string"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from statsmodels.graphics.regressionplots import *\n",
    "from scipy.stats import zscore\n",
    "y_pred = lm1_fit.predict(sm.add_constant(Auto['horsepower']))\n",
    "\n",
    "lm1_resid = lm1_fit.resid # residuals\n",
    "lm1_resid_stud = lm1_fit.get_influence().resid_studentized_internal # studentized residuals\n",
    "\n",
    "norm_resid = zscore(lm1_resid)\n",
    "leverage = lm1_fit.get_influence().hat_matrix_diag\n",
    "\n",
    "f, axes = plt.subplots(2, 2, sharex=False, sharey=False) \n",
    "f.set_figheight(10)\n",
    "f.set_figwidth(15)\n",
    "\n",
    "sns.regplot('horsepower', 'mpg', data=Auto, ax=axes[0, 0], scatter_kws={'alpha': '0.5'}) # regression plot\n",
    "sns.residplot(y_pred, 'mpg', data=Auto, ax=axes[0, 1], lowess=True, \n",
    "              scatter_kws={'alpha': '0.5'},\n",
    "              line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8}) # residual plot\n",
    "\n",
    "# leverage plot\n",
    "\n",
    "norm_resid = zscore(lm1_resid)\n",
    "leverage = lm1_fit.get_influence().hat_matrix_diag\n",
    "axes[1, 0].autoscale(enable=True, axis='y', tight=True)\n",
    "axes[1, 0].scatter(norm_resid ** 2, leverage, alpha=0.5, color='red')\n",
    "\n",
    "# studentized residual plot\n",
    "axes[1, 1].scatter(y_pred, lm1_resid_stud, alpha=0.5, color='magenta')\n",
    "sns.regplot(y_pred, lm1_resid_stud, ax=axes[1, 1], scatter=False, ci=False, lowess=True,\n",
    "            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "axes[1, 1].axhline(0, ls=\":\", c=\".2\")\n",
    "axes[1, 1].axhline(-3, ls=\":\", c=\".6\")\n",
    "axes[1, 1].axhline(3, ls=\":\", c=\".6\")\n",
    "axes[1, 1].set_xlim(0, 35);\n",
    "axes[1, 1].set_ylim(-5, 5);\n",
    "\n",
    "x = y_pred[np.logical_or(lm1_resid_stud > 3, lm1_resid_stud < -3)]\n",
    "y = lm1_resid_stud[np.logical_or(lm1_resid_stud > 3, lm1_resid_stud < -3)]\n",
    "\n",
    "for i, x, y in zip(x.index, x, y):\n",
    "    axes[1, 1].annotate(i, xy=(x, y));\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0314ebf957664a55db46b44e96ea611994405d14351282b365ae6c7dbed92203"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
